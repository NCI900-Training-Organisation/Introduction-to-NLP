{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Text Processing\n",
    "In order to feed text data to a deep learning model, we need to prepare the data through some common procedures. In this notebook, we will cover data cleaning and use the clean words to create a wordcloud. These processed words will also be used as input for our first RNN model.   \n",
    "\n",
    "**Outline**  \n",
    "- Load and inspect the dataset  \n",
    "- Clean data and generate tokens\n",
    "- Generate dataset tokens and a wordcloud  \n",
    "- Use cleaned data to perform sentiment analysis using logistic regression \n",
    "  \n",
    "**Estimated time:** \n",
    " 30 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change notebook directory, for Gadi environment only\n",
    "import os\n",
    "working_path = os.path.expandvars(\"/scratch/vp91/$USER/Introduction-to-NLP/\")\n",
    "os.chdir(working_path)\n",
    "data_path = '/scratch/vp91/NLP-2024/data/'\n",
    "model_path = '/scratch/vp91/NLP-2024/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local paths\n",
    "# working_path = './'\n",
    "# data_path = '../data/'\n",
    "# model_path = '../model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text processing\n",
    "import nltk\n",
    "# nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "\n",
    "#for inspecting data\n",
    "import pandas as pd\n",
    "\n",
    "# for plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# store the data\n",
    "import pickle\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(data_path+'Sarcasm_Headlines_Dataset_v2.json',lines=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we check if there is any empty values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can count the number of documents in each labeled category to see if this is a balanced dataset. If the dataset is unbalanced, the learning outcome will be biased since some label has more data to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the data for different labels\n",
    "sns.countplot(data.is_sarcastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I explored the number of words in each document for different category, and found that the non-sarcastic text is close to a normal distribution while the sarcastic ones are shorter and clustered together. Feel free to explore more in the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "text_len=data[data['is_sarcastic']==1]['headline'].str.split().map(lambda x: len(x))\n",
    "ax1.hist(text_len,color='red')\n",
    "ax1.set_title('Sarcastic text')\n",
    "text_len=data[data['is_sarcastic']==0]['headline'].str.split().map(lambda x: len(x))\n",
    "ax2.hist(text_len,color='green')\n",
    "ax2.set_title('Not Sarcastic text')\n",
    "fig.suptitle('Words in texts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "## Data Cleaning  \n",
    "There is a chance that the data you have are neatly printed for each record and all words are vital to your project goal, but more often is that you have some text from web pages with HTML tags still in them, or extra spaces, or the data quality is really inconsistant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = [h for h in data.headline]\n",
    "headlines[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    text = text.lower().strip()\n",
    "    # TODO remove the digits\n",
    "    text = \n",
    "    # TODO remove the punctuations\n",
    "    text = \n",
    "    text = ''.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = [cleanText(t) for t in headlines]\n",
    "headlines[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Task 1.</b>Write a function to:<br>\n",
    " 1. remove extra spaces  <br>\n",
    " 2. change all text to lowercase   <br>\n",
    " 3. remove all digits  <br>\n",
    " 4. remove punctuations  <br>\n",
    "  \n",
    "</div>  \n",
    "\n",
    "Below are some common build-in string functions in python, which are good starting points if you don't usually handle string data.  \n",
    "\n",
    "**String functions:**   \n",
    " \n",
    "- `str.lower()`\n",
    "Return a copy of the string with all the cased characters 4 converted to lowercase.  \n",
    "\n",
    "- `str.replace(old, new[, count])`\n",
    "Return a copy of the string with all occurrences of substring old replaced by new. If the optional argument count is given, only the first count occurrences are replaced.  \n",
    "\n",
    "- `str.strip([chars])`\n",
    "Return a copy of the string with the leading and trailing characters removed.  \n",
    "\n",
    "- `str.isalnum()`\n",
    "Return True if all characters in the string are alphanumeric and there is at least one character, False otherwise.  \n",
    "\n",
    "- `str.isdigit()`\n",
    "Return True if all characters in the string are digits and there is at least one character, False otherwise.  \n",
    "\n",
    "- `string.punctuation`\n",
    "String of ASCII characters which are considered punctuation characters in the C locale: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~.  \n",
    "\n",
    "[Full Python String Methods Doc](https://docs.python.org/3.7/library/stdtypes.html#string-methods)  \n",
    "  \n",
    "  \n",
    "**Regular Expressions:**\n",
    "- Matching characters  \n",
    "    `[]` They represent a set of characters you wish to match. For example, `[abc]` will match `'a'`, `'b'` or `'c'`.  It also accepts a range of characters, i.e. `[a-c]` is equivilent to `[abc]`.  \n",
    "\n",
    "    `\\w` This matches any alphanumeric character, which is equivalent to `[a-zA-Z0-9_]`.  \n",
    "    \n",
    "    `\\d` This matches any decimal digit, which is equivalent to `[0-9]`.\n",
    "    \n",
    "    `\\s` This matches any whitespace, which is equivalent to `[ \\t\\n\\r\\f\\v]`.   \n",
    "    \n",
    "    It can also match the complementing set by uppercase `\\W`, `\\D`, `\\S`, or adding `^` at the beginning of a class. For example, `\\D` matches anything but decimal digits, and it is equivilant to `[^0-9]`.  \n",
    "\n",
    "- Matching repetitions  \n",
    "    `*` specifies that the character before it may appear 0 or more times.  \n",
    "    \n",
    "    `+` specifies that the character before it appears at least 1 time.  \n",
    "    \n",
    "    `?` matches 0 or 1 time occurrence.  \n",
    "    \n",
    "    `{m,n}` matches at least m occurrence and at most n occurrence.  \n",
    "- Functions   \n",
    "    `re.sub(pattern, repl, string, count=0, flags=0)`  Returns the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl. If the pattern isnâ€™t found, string is returned unchanged. repl can be a string or a function  \n",
    "\n",
    "\n",
    "[Regular Expression HOWTO - a gentle explanation](https://docs.python.org/3/howto/regex.html#regex-howto)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">   \n",
    ">Think:  \n",
    "> 1. Does the order of processing in your function matter? \n",
    "> 2. What would your function do if `<br />` become `</jats:p>` or other stuffs are inside?\n",
    "> 3. What would your function return if there are `(...)` contents in the string?    \n",
    "> 4. How clean should the data be?  \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Challenge:</b> <br>\n",
    "Write the `cleanAText(text)` function for this dirtier short paragraph and return a clean version of text.\n",
    "</div>  \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"     Many people thought that this is a good movie but I don't agree with them. At the beginning of the movie, a spaceship crushed on earth and some of the aliens escaped from the spaceship, then hey killed some people on the earth, but for no reason. Also, it is in a dark forest, I can't see anything on the screen, I can only hardly hear the sound.<br />             <br />After a few days, the predator came to the earth but no one had sent signals to him before that, he should not know what happened on the earth, so there is a contradiction. Finally, the predator found the headmaster (of the aliens) and killed it for no reason. He was not live on earth, t is none of his business about the things happened here. Lastly, the duration of the movie is only 90 minutes long, the summary is too short and it can't tell the reviewers about the story clearly.<br /><br />In conclusion, I don't think this is a good movie.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanAText(text):\n",
    "    # TODO\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanAText(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenisation, Remove Stopwords and Stemming  \n",
    "There are a range of libraries that can achieve these steps. For this tutorial, we will use the good old `nltk`.   \n",
    "We use the `word_tokenize` function from the package to get word tokens. `nltk` also has `sent_tokenize` that tokenize a paragraph into sentences.   \n",
    "We also import the build-in stopwords from the package. The `nltk.corpus.stopwords` includes multiple language versions and we can have a look at the english version below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize('This is an tokenisation example.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordNetLemmatizer().lemmatize('works')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Task 2. Fill in nltk_token function </b>  <br>\n",
    "1. Remove stopwords using nltk stopwords set <br>\n",
    "2. Run the code to plot token frequency and wordcloud<br>\n",
    "3. Examine your plot and wordcloud, improve the text cleaning functions<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_token(text):    \n",
    "    # TODO tokenisation: get the list of tokens\n",
    "    tokens = \n",
    "\n",
    "    # TODO remove stopwords\n",
    "    stopwords_set = set(stopwords.words('english')) \n",
    "\n",
    "    tokens = \n",
    "    # lemmatization\n",
    "    tokens = [WordNetLemmatizer().lemmatize(w) for w in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [nltk_token(t) for t in headlines]\n",
    "tokens[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put the `cleanText()` and `nltk_token` together to call it a `processText` function and return the cleaned headlines instead of tokens. Then we apply this function to our dataframe, headline column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processText(text):\n",
    "    text = cleanText(text)\n",
    "    tokens = nltk_token(text)\n",
    "    text = ' '.join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data.copy()\n",
    "data_clean.headline = data.headline.apply(processText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save tokens and cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(working_path+ 'tokens.pkl', 'wb') as f:\n",
    "    pickle.dump(tokens, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(working_path+ 'data_clean.pkl', 'wb') as f:\n",
    "    pickle.dump(data_clean, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Token Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## total number of unique tokens in the collection\n",
    "tokens = [token for l in tokens for token in l]\n",
    "unique = set(tokens)\n",
    "print(\"Number of unique tokens in the dataset: {}\".format(len(unique)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = nltk.FreqDist(tokens)\n",
    "\n",
    "# print the top tokens\n",
    "top_tokens = freq.most_common(20)\n",
    "print(top_tokens)\n",
    "\n",
    "# plot the distribution\n",
    "token = [t[0] for t in top_tokens]\n",
    "count = [t[1] for t in top_tokens]\n",
    "plt.figure(figsize=(15, 6))  \n",
    "sns.barplot(count, token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cloud(wordcloud):\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # Display image\n",
    "    plt.imshow(wordcloud) \n",
    "    # No axis details\n",
    "    plt.axis(\"off\")\n",
    "# tokens list to string\n",
    "str_tokens = ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improve word cloud with more stopwords removal\n",
    "# Generate word cloud\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, \n",
    "                      background_color='black',colormap='Set3', \n",
    "                      include_numbers=False,\n",
    "                      collocations=False, max_words=500, \n",
    "                      ).generate(str_tokens)\n",
    "# Plot\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Classification  \n",
    "In this section we will demonstrate the basic implementation for classification tasks using `sklearn` model.\n",
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use the `train_test_split` module for data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data_clean['is_sarcastic'].values\n",
    "data_clean.drop(['is_sarcastic'], axis=1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_clean, y, test_size=0.3, stratify=y)\n",
    "\n",
    "print(\"Train data:\",  X_train.shape, y_train.shape)\n",
    "print(\"Test data:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(min_df=10)\n",
    "\n",
    "X_train_review_bow = vect.fit_transform(X_train['headline'])\n",
    "X_test_review_bow = vect.transform(X_test['headline'])\n",
    "\n",
    "print('X_train_review_bow shape: ', X_train_review_bow.shape)\n",
    "print('X_test_review_bow shape: ', X_test_review_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_review_bow, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_review_bow)\n",
    "print('Test Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Did the model converge? If not, try to modify it according to the warning message. [Hint](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try the tf-idf representation and see if this has better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "\n",
    "X_train_review_tfidf = vectorizer.fit_transform(X_train['headline'])\n",
    "X_test_review_tfidf = vectorizer.transform(X_test['headline'])\n",
    "\n",
    "print('X_train_review_tfidf shape: ', X_train_review_tfidf.shape)\n",
    "print('X_test_review_tfidf shape: ', X_test_review_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_review_tfidf, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_review_tfidf)\n",
    "print('Test Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Test Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------  \n",
    "\n",
    "Next:  \n",
    "You will proceed to [notebook 2](2-Glove-Embedding.ipynb) and build your RNN model for classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4f5d7df9eebeb2fce5c7cb4fadb86274017838dfb7de8d5dd5849e5abb02796"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
